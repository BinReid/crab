from flask import Flask, render_template, request, jsonify, session
import numpy as np
import json
import os
from datetime import datetime
import joblib
import pickle
import sys
from collections import Counter

app = Flask(__name__)
app.secret_key = 'your-secret-key-here'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
classifier = None
vectorizer = None
class_mapping = None
optimized_classes = None
confidence_threshold = 0.7

def numpy_to_python(obj):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è NumPy —Ç–∏–ø–æ–≤ –≤ Python —Ç–∏–ø—ã –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {k: numpy_to_python(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [numpy_to_python(item) for item in obj]
    else:
        return obj

def load_model_and_config():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    global classifier, vectorizer, class_mapping, optimized_classes, confidence_threshold
    
    try:
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        classifier = joblib.load('models/best_model_random_forest.joblib')
        original_classes = [str(c) for c in classifier.classes_]
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ö–ª–∞—Å—Å–æ–≤: {len(original_classes)}")
        
        # 2. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞...")
        vectorizer = joblib.load('models/tfidf_vectorizer.joblib')
        print("–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω.")
        
        # 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config_path = 'model_config_final.json'
        if os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            class_mapping = config.get('class_mapping', {})
            optimized_classes = config.get('optimized_classes', [])
            confidence_threshold = config.get('threshold', 0.7)
            print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(optimized_classes)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        else:
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–∞–ø–ø–∏–Ω–≥
            print("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞...")
            class_mapping = create_simple_mapping(original_classes)
            optimized_classes = sorted(list(set(class_mapping.values())))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config = {
                'optimized_classes': optimized_classes,
                'threshold': 0.7,
                'class_mapping': class_mapping,
                'model_info': {
                    'type': 'random_forest',
                    'n_original_classes': len(original_classes),
                    'n_optimized_classes': len(optimized_classes),
                    'version': '1.0'
                }
            }
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            print(f"–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {len(optimized_classes)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")
        
        return True
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_simple_mapping(original_classes):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤"""
    mapping = {}
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for cls in original_classes:
        cls_str = str(cls)
        
        # –ú–∞–ø–ø–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–æ–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Å–æ–≤
        if cls_str in ['14', '12', '11', '17', '10', '13']:
            mapping[cls_str] = '–ø—Ä–æ–±–ª–µ–º–∞_–ø–æ–ª—É—á–µ–Ω–∏—è_–∑–∞–∫–∞–∑–∞'
        elif cls_str in ['15', '9', '20', '19', '21']:
            mapping[cls_str] = '–ø–æ–∏—Å–∫_–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞'
        elif cls_str in ['23', '22', '24', '25', '26']:
            mapping[cls_str] = '—Å–≤—è–∑—å_—Å_–æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º'
        elif cls_str in ['16', '18', '27', '28', '29']:
            mapping[cls_str] = '–ø—Ä–æ–±–ª–µ–º–∞_—Å_–ø–æ—Å—Ç–∞–º–∞—Ç–æ–º'
        elif cls_str in ['8', '7', '6', '5', '4']:
            mapping[cls_str] = '–∏–∑–º–µ–Ω–µ–Ω–∏–µ_–∑–∞–∫–∞–∑–∞'
        elif cls_str in ['0', '1', '2', '3', '30', '31']:
            mapping[cls_str] = '—É—Ç–æ—á–Ω–µ–Ω–∏–µ_–¥–æ—Å—Ç–∞–≤–∫–∏'
        elif cls_str in ['32', '33', '34', '35']:
            mapping[cls_str] = '–æ–ø–ª–∞—Ç–∞_–≤–æ–∑–≤—Ä–∞—Ç'
        else:
            mapping[cls_str] = '–æ–±—â–∏–π_–≤–æ–ø—Ä–æ—Å'
    
    return mapping

def predict_intent(text):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    global classifier, vectorizer, class_mapping, confidence_threshold
    
    if not classifier or not vectorizer:
        return None
    
    try:
        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        features = vectorizer.transform([text])
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        probabilities = classifier.predict_proba(features)[0]
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º
        optimized_probs = {}
        
        for i, orig_class in enumerate(classifier.classes_):
            prob = float(probabilities[i])  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ä–∞–∑—É –≤ float
            orig_class_str = str(orig_class)
            opt_class = class_mapping.get(orig_class_str, '–æ–±—â–∏–π_–≤–æ–ø—Ä–æ—Å')
            
            if opt_class not in optimized_probs:
                optimized_probs[opt_class] = 0.0
            optimized_probs[opt_class] += prob
        
        # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        best_class = max(optimized_probs, key=optimized_probs.get)
        best_confidence = float(optimized_probs[best_class])
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-3
        sorted_classes = sorted(optimized_probs.items(), key=lambda x: x[1], reverse=True)
        top_3 = sorted_classes[:3]
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'text': text,
            'main_intent': best_class,
            'main_confidence': best_confidence,
            'is_confident': bool(best_confidence >= confidence_threshold),  # –Ø–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ bool
            'all_predictions': [
                {
                    'intent': intent,
                    'confidence': float(conf),
                    'is_confident': bool(conf >= confidence_threshold)
                }
                for intent, conf in top_3
            ],
            'optimized_probabilities': {k: float(v) for k, v in optimized_probs.items()}
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        best_original_idx = int(np.argmax(probabilities))
        best_original_class = str(classifier.classes_[best_original_idx])
        best_original_prob = float(probabilities[best_original_idx])
        
        result['original_prediction'] = {
            'class': best_original_class,
            'confidence': best_original_prob
        }
        
        # –¢–æ–ø-3 –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤
        top_original_indices = np.argsort(probabilities)[-3:][::-1]
        original_top = []
        for idx in top_original_indices:
            original_top.append({
                'class': str(classifier.classes_[int(idx)]),  # –Ø–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ int
                'confidence': float(probabilities[int(idx)])
            })
        result['original_top3'] = original_top
        
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return None

# –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤
class QueryHistory:
    def __init__(self):
        self.history = []
    
    def add_query(self, text, result):
        # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç numpy —Ç–∏–ø–æ–≤
        cleaned_result = numpy_to_python(result)
        self.history.append({
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'text': text,
            'result': cleaned_result
        })
        if len(self.history) > 50:
            self.history = self.history[-50:]
    
    def get_history(self):
        return self.history
    
    def clear_history(self):
        self.history = []

history = QueryHistory()

# –ú–∞—Ä—à—Ä—É—Ç—ã Flask
@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    categories = optimized_classes if optimized_classes else []
    
    return render_template('index.html',
                         classifier_loaded=classifier is not None,
                         categories=categories)

@app.route('/classify', methods=['POST'])
def classify_text():
    """API –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
    if not classifier:
        return jsonify({
            'success': False,
            'error': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'
        })
    
    try:
        data = request.get_json()
        if not data or 'text' not in data:
            return jsonify({
                'success': False,
                'error': '–¢–µ–∫—Å—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'
            })
        
        text = data['text'].strip()
        if not text:
            return jsonify({
                'success': False,
                'error': '–¢–µ–∫—Å—Ç –ø—É—Å—Ç'
            })
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        result = predict_intent(text)
        if not result:
            return jsonify({
                'success': False,
                'error': '–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏'
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        history.add_query(text, result)
        
        # –î–æ–±–∞–≤–ª—è–µ–º timestamp
        result['timestamp'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        result['success'] = True
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy —Ç–∏–ø—ã
        cleaned_result = numpy_to_python(result)
        
        return jsonify(cleaned_result)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ /classify: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/batch_classify', methods=['POST'])
def batch_classify():
    """API –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    if not classifier:
        return jsonify({
            'success': False,
            'error': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'
        })
    
    try:
        data = request.get_json()
        if not data or 'texts' not in data:
            return jsonify({
                'success': False,
                'error': '–¢–µ–∫—Å—Ç—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã'
            })
        
        texts = data['texts']
        if not isinstance(texts, list):
            return jsonify({
                'success': False,
                'error': '–¢–µ–∫—Å—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º'
            })
        
        if len(texts) > 100:
            texts = texts[:100]
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        results = []
        for text in texts:
            if isinstance(text, str) and text.strip():
                result = predict_intent(text.strip())
                if result:
                    cleaned_result = {
                        'text': text.strip(),
                        'main_intent': str(result['main_intent']),
                        'main_confidence': float(result['main_confidence']),
                        'is_confident': bool(result['is_confident'])
                    }
                    results.append(cleaned_result)
        
        response = {
            'success': True,
            'total_texts': len(texts),
            'processed_texts': len(results),
            'results': results,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return jsonify(response)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ /batch_classify: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/upload_file', methods=['POST'])
def upload_file():
    """API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ —Å —Ç–µ–∫—Å—Ç–∞–º–∏"""
    if not classifier:
        return jsonify({
            'success': False,
            'error': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'
        })
    
    try:
        if 'file' not in request.files:
            return jsonify({
                'success': False,
                'error': '–§–∞–π–ª –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω'
            })
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({
                'success': False,
                'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'
            })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
        allowed_extensions = ['.txt', '.csv']
        if not any(file.filename.endswith(ext) for ext in allowed_extensions):
            return jsonify({
                'success': False,
                'error': '–†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã .txt –∏ .csv'
            })
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        content = file.read().decode('utf-8', errors='ignore')
        
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç—ã
        texts = [line.strip() for line in content.split('\n') if line.strip()]
        
        if len(texts) > 1000:
            texts = texts[:1000]
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        results = []
        for text in texts:
            result = predict_intent(text)
            if result:
                cleaned_result = {
                    'text': text,
                    'main_intent': str(result['main_intent']),
                    'main_confidence': float(result['main_confidence']),
                    'is_confident': bool(result['is_confident'])
                }
                results.append(cleaned_result)
        
        response = {
            'success': True,
            'filename': file.filename,
            'total_texts': len(texts),
            'results': results,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return jsonify(response)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ /upload_file: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/history')
def get_history():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤"""
    history_data = history.get_history()
    response = {
        'success': True,
        'history': history_data,
        'total_queries': len(history_data)
    }
    
    return jsonify(response)

@app.route('/clear_history', methods=['POST'])
def clear_history():
    """–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –∑–∞–ø—Ä–æ—Å–æ–≤"""
    history.clear_history()
    return jsonify({
        'success': True,
        'message': '–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞'
    })

@app.route('/classifier_info')
def classifier_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ"""
    if not classifier:
        return jsonify({
            'success': False,
            'error': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'
        })
    
    try:
        info = {
            'success': True,
            'original_classes': len(classifier.classes_),
            'optimized_classes': len(optimized_classes) if optimized_classes else 0,
            'categories': optimized_classes if optimized_classes else [],
            'confidence_threshold': float(confidence_threshold),
            'model_info': {
                'type': 'random_forest',
                'n_original_classes': len(classifier.classes_),
                'n_optimized_classes': len(optimized_classes) if optimized_classes else 0,
                'version': '1.0'
            }
        }
        
        return jsonify(info)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ /classifier_info: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/statistics')
def get_statistics():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    history_data = history.get_history()
    
    stats = {
        'success': True,
        'total_queries': len(history_data),
        'queries_today': len([q for q in history_data 
                             if q['timestamp'].startswith(datetime.now().strftime('%Y-%m-%d'))]),
        'categories_used': {},
        'confidence_stats': {
            'avg_confidence': 0.0,
            'confident_queries': 0
        }
    }
    
    # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    for query in history_data:
        intent = query['result'].get('main_intent')
        if intent:
            if intent not in stats['categories_used']:
                stats['categories_used'][intent] = 0
            stats['categories_used'][intent] += 1
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = float(query['result'].get('main_confidence', 0))
        stats['confidence_stats']['avg_confidence'] += confidence
        if confidence >= confidence_threshold:
            stats['confidence_stats']['confident_queries'] += 1
    
    # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    if history_data:
        stats['confidence_stats']['avg_confidence'] = float(stats['confidence_stats']['avg_confidence'] / len(history_data))
    
    return jsonify(stats)

@app.route('/example_queries')
def example_queries():
    """–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    examples = [
        {"text": "–Ω–µ –º–æ–≥—É –ø–æ–ª—É—á–∏—Ç—å –ø–æ—Å—ã–ª–∫—É", "category": "–ø—Ä–æ–±–ª–µ–º–∞_–ø–æ–ª—É—á–µ–Ω–∏—è_–∑–∞–∫–∞–∑–∞"},
        {"text": "–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –º–æ—è –ø–æ—Å—ã–ª–∫–∞", "category": "–ø–æ–∏—Å–∫_–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞"},
        {"text": "—Å–æ–µ–¥–∏–Ω–∏—Ç–µ —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º", "category": "—Å–≤—è–∑—å_—Å_–æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º"},
        {"text": "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–æ—Å—Ç–∞–º–∞—Ç", "category": "–ø—Ä–æ–±–ª–µ–º–∞_—Å_–ø–æ—Å—Ç–∞–º–∞—Ç–æ–º"},
        {"text": "–ø–µ—Ä–µ–Ω–µ—Å—Ç–∏ —Å—Ä–æ–∫ –¥–æ—Å—Ç–∞–≤–∫–∏", "category": "–∏–∑–º–µ–Ω–µ–Ω–∏–µ_–∑–∞–∫–∞–∑–∞"},
        {"text": "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "category": "–æ–±—â–∏–π_–≤–æ–ø—Ä–æ—Å"},
        {"text": "–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç—Å—è —è—á–µ–π–∫–∞", "category": "–ø—Ä–æ–±–ª–µ–º–∞_–ø–æ–ª—É—á–µ–Ω–∏—è_–∑–∞–∫–∞–∑–∞"},
        {"text": "–∫–∞–∫ –æ—Ç—Å–ª–µ–¥–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "category": "–ø–æ–∏—Å–∫_–æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ_–∑–∞–∫–∞–∑–∞"},
        {"text": "–Ω—É–∂–µ–Ω –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç", "category": "—Å–≤—è–∑—å_—Å_–æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º"},
        {"text": "–Ω–µ –ø—Ä–∏—à–µ–ª –∫–æ–¥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è", "category": "–ø—Ä–æ–±–ª–µ–º–∞_—Å_–ø–æ—Å—Ç–∞–º–∞—Ç–æ–º"}
    ]
    
    return jsonify({
        'success': True,
        'examples': examples,
        'total_examples': len(examples)
    })

@app.route('/test_connection')
def test_connection():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—É"""
    test_phrase = "—Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å"
    
    if not classifier:
        return jsonify({
            'success': False,
            'status': 'classifier_not_loaded',
            'message': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω'
        })
    
    try:
        result = predict_intent(test_phrase)
        if result:
            # –û—á–∏—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            cleaned_result = numpy_to_python(result)
            response = {
                'success': True,
                'status': 'working',
                'test_phrase': test_phrase,
                'result': cleaned_result,
                'message': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ'
            }
            return jsonify(response)
        else:
            return jsonify({
                'success': False,
                'status': 'error',
                'message': '–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è'
            })
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ /test_connection: {e}")
        return jsonify({
            'success': False,
            'status': 'error',
            'message': str(e)
        })

if __name__ == '__main__':
    print("="*60)
    print("Flask –≤–µ–±-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∏–Ω—Ç–µ–Ω—Ç–æ–≤")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model_loaded = load_model_and_config()
    
    if model_loaded:
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤: {len(classifier.classes_)}")
        print(f"   –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(optimized_classes)}")
        print(f"   –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {confidence_threshold}")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {optimized_classes}")
    else:
        print("‚ùå –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å!")
        print("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ –ø–∞–ø–∫–µ models/")
        print("   –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã:")
        print("   - models/best_model_random_forest.joblib")
        print("   - models/tfidf_vectorizer.joblib")
    
    print("\nüåê –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://localhost:5000")
    print("   –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    print("="*60)
    
    app.run(debug=True, host='0.0.0.0', port=5000)